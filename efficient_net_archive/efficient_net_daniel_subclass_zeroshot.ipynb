{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 16:11:44.825866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielum/Library/Mobile Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass_zeroshot.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass_zeroshot.ipynb#W0sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m# Add custom top layers\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass_zeroshot.ipynb#W0sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m x \u001b[39m=\u001b[39m GlobalAveragePooling2D()(base_model\u001b[39m.\u001b[39moutput)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass_zeroshot.ipynb#W0sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m output \u001b[39m=\u001b[39m Dense(all_subclass_names, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)(x) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass_zeroshot.ipynb#W0sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mbase_model\u001b[39m.\u001b[39minput, outputs\u001b[39m=\u001b[39moutput)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass_zeroshot.ipynb#W0sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/dtensor/utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[39mif\u001b[39;00m layout:\n\u001b[1;32m     94\u001b[0m             layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[0;32m---> 96\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:119\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@utils\u001b[39m\u001b[39m.\u001b[39mallow_initializer_layout\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    116\u001b[0m ):\n\u001b[1;32m    117\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(activity_regularizer\u001b[39m=\u001b[39mactivity_regularizer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(units) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(units, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m units\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    121\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReceived an invalid value for `units`, expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ma positive integer. Received: units=\u001b[39m\u001b[39m{\u001b[39;00munits\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/train_data.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')\n",
    "\n",
    "# Superclass_name (can replace with subclass_name depending on classification task)\n",
    "train_data_df['class'] = train_data_df['subclass_name']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, validation_df = train_test_split(train_data_df, test_size=0.2)\n",
    "\n",
    "# Initialize the ImageDataGenerator with EfficientNet's preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'Released_Data/train_shuffle'\n",
    "\n",
    "def custom_generator(df, image_folder_path, batch_size):\n",
    "    num_samples = len(df)\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = df.iloc[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            labels = []\n",
    "            for _, row in batch_samples.iterrows():\n",
    "                # Load image and preprocess\n",
    "                image_path = os.path.join(image_folder_path, row['image'])\n",
    "                image = load_and_preprocess_image(image_path)  # Define this function as per your preprocessing needs\n",
    "                images.append(image)\n",
    "\n",
    "                # Get one-hot encoded label\n",
    "                label_index = class_name_to_index[row['subclass_name']]\n",
    "                label = to_categorical(label_index, num_classes=len(all_class_names))\n",
    "                labels.append(label)\n",
    "\n",
    "            # Yield the next batch of images and labels\n",
    "            yield np.array(images), np.array(labels)\n",
    "\n",
    "train_generator = custom_generator(train_df, image_folder_path=image_folder_path, batch_size=32)\n",
    "validation_generator = custom_generator(validation_df, image_folder_path=image_folder_path, batch_size=32)\n",
    "# Load and preprocess images for training\n",
    "# train_generator = datagen.flow_from_dataframe(\n",
    "#     dataframe=train_df,\n",
    "#     directory=image_folder_path,\n",
    "#     x_col='image',\n",
    "#     y_col='class',\n",
    "#     class_mode='categorical',\n",
    "#     target_size=(300, 300),\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# # Load and preprocess images for validation\n",
    "# validation_generator = datagen.flow_from_dataframe(\n",
    "#     dataframe=validation_df,\n",
    "#     directory=image_folder_path,\n",
    "#     x_col='image',\n",
    "#     y_col='class',\n",
    "#     class_mode='categorical',\n",
    "#     target_size=(300, 300),\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# Load pre-trained EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Actual number of subclasses: \n",
    "all_subclass_names = sub_classes_df['subclass_name'].tolist()\n",
    "\n",
    "# Add custom top layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(all_subclass_names, activation='softmax')(x) \n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subclass_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Scotch terrier, Scottish terrier, Scottie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>African chameleon, Chamaeleo chamaeleon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>standard schnauzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>terrapin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>great grey owl, great gray owl, Strix nebulosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>robin, American robin, Turdus migratorius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>magpie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>miniature schnauzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>European gallinule, Porphyrio porphyrio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                   subclass_name\n",
       "0       0       Scotch terrier, Scottish terrier, Scottie\n",
       "1       1         African chameleon, Chamaeleo chamaeleon\n",
       "2       2                              standard schnauzer\n",
       "3       3                                        terrapin\n",
       "4       4  great grey owl, great gray owl, Strix nebulosa\n",
       "..    ...                                             ...\n",
       "83     83       robin, American robin, Turdus migratorius\n",
       "84     84                                          magpie\n",
       "85     85                             miniature schnauzer\n",
       "86     86         European gallinule, Porphyrio porphyrio\n",
       "87     87                                           novel\n",
       "\n",
       "[88 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subclasses: 87\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique subclass indices\n",
    "num_subclasses = train_data_df['subclass_index'].nunique()\n",
    "print(\"Number of unique subclasses:\", num_subclasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/usr/local/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/usr/local/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/q3/wpwyjkzs2rgbb597cc6zg74m0000gn/T/ipykernel_14336/818116670.py\", line 2, in <module>\n      model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/backend.py\", line 5566, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,88] labels_size=[32,87]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_93625]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielum/Library/Mobile Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train_generator, validation_data\u001b[39m=\u001b[39mvalidation_generator, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Unfreeze some layers for fine-tuning\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_subclass.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m base_model\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]:\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/usr/local/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/usr/local/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/q3/wpwyjkzs2rgbb597cc6zg74m0000gn/T/ipykernel_14336/818116670.py\", line 2, in <module>\n      model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/backend.py\", line 5566, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,88] labels_size=[32,87]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_93625]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_folder = 'Released_Data/test_shuffle'   # Correct path to your test images\n",
    "image_files = [os.path.join(test_image_folder, img) for img in os.listdir(test_image_folder) if img.endswith('.jpg')]\n",
    "test_df = pd.DataFrame(image_files, columns=['filename'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Released_Data/test_shuffle/9733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Released_Data/test_shuffle/63.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Released_Data/test_shuffle/6400.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Released_Data/test_shuffle/823.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Released_Data/test_shuffle/4217.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename\n",
       "0  Released_Data/test_shuffle/9733.jpg\n",
       "1    Released_Data/test_shuffle/63.jpg\n",
       "2  Released_Data/test_shuffle/6400.jpg\n",
       "3   Released_Data/test_shuffle/823.jpg\n",
       "4  Released_Data/test_shuffle/4217.jpg"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 1480s 4s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12377, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: True\n",
      "Train DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "4468  4468.jpg                 2              44        2         reptile   \n",
      "3498  3498.jpg                 0              28        0            bird   \n",
      "6148  6148.jpg                 0              30        0            bird   \n",
      "354    354.jpg                 1              31        1             dog   \n",
      "4655  4655.jpg                 2              69        2         reptile   \n",
      "\n",
      "      index_y                                      subclass_name    class  \n",
      "4468       44              hognose snake, puff adder, sand viper  reptile  \n",
      "3498       28                                       black grouse     bird  \n",
      "6148       30                                            vulture     bird  \n",
      "354        31                                           Shih-Tzu      dog  \n",
      "4655       69  leatherback turtle, leatherback, leathery turt...  reptile  \n",
      "Validation DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "131    131.jpg                 0              26        0            bird   \n",
      "923    923.jpg                 2              15        2         reptile   \n",
      "940    940.jpg                 0              57        0            bird   \n",
      "1930  1930.jpg                 0              19        0            bird   \n",
      "3040  3040.jpg                 0              27        0            bird   \n",
      "\n",
      "      index_y                        subclass_name    class  \n",
      "131        26                 albatross, mollymawk     bird  \n",
      "923        15                           mud turtle  reptile  \n",
      "940        57                               bulbul     bird  \n",
      "1930       19  brambling, Fringilla montifringilla     bird  \n",
      "3040       27                  water ouzel, dipper     bird  \n",
      "Length of train_df: 5177\n",
      "Length of validation_df: 1295\n",
      "4468.jpg exists: True\n",
      "3498.jpg exists: True\n",
      "6148.jpg exists: True\n",
      "354.jpg exists: True\n",
      "4655.jpg exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Check the directory path\n",
    "print(\"Directory exists:\", os.path.isdir(image_folder_path))\n",
    "\n",
    "# Check the first few rows of train_df and validation_df\n",
    "print(\"Train DataFrame:\\n\", train_df.head())\n",
    "print(\"Validation DataFrame:\\n\", validation_df.head())\n",
    "\n",
    "# Check the length of the DataFrames\n",
    "print(\"Length of train_df:\", len(train_df))\n",
    "print(\"Length of validation_df:\", len(validation_df))\n",
    "\n",
    "# Check a few image file paths\n",
    "sample_images = train_df['image'].head().tolist()\n",
    "for img in sample_images:\n",
    "    file_path = os.path.join(image_folder_path, img)\n",
    "    print(f\"{img} exists:\", os.path.isfile(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_csv(\"/res/superclass_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
