{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 14:39:56.954965: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Released_Data/train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielum/Library/Mobile Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Load the CSV files\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_data_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mReleased_Data/train_data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m super_classes_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mReleased_Data/super_classes_mapping.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m sub_classes_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mReleased_Data/sub_classes_mapping.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Released_Data/train_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/train_data.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/super_classes_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/sub_classes_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')\n",
    "\n",
    "# Superclass_name (can replace with subclass_name depending on classification task)\n",
    "train_data_df['class'] = train_data_df['superclass_name']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, validation_df = train_test_split(train_data_df, test_size=0.2)\n",
    "\n",
    "# Initialize the ImageDataGenerator with EfficientNet's preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'Released_Data/train_shuffle'\n",
    "\n",
    "# Load and preprocess images for training\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load and preprocess images for validation\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(len(super_classes_df), activation='softmax')(x) # Number of classes\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 810s 5s/step - loss: 0.8752 - accuracy: 0.5940 - val_loss: 0.7654 - val_accuracy: 0.6749\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 786s 5s/step - loss: 0.7729 - accuracy: 0.6612 - val_loss: 0.7502 - val_accuracy: 0.6819\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 791s 5s/step - loss: 0.7368 - accuracy: 0.6813 - val_loss: 0.7336 - val_accuracy: 0.6981\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 791s 5s/step - loss: 0.7198 - accuracy: 0.6977 - val_loss: 0.7182 - val_accuracy: 0.7073\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 788s 5s/step - loss: 0.7003 - accuracy: 0.7025 - val_loss: 0.7092 - val_accuracy: 0.7066\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 793s 5s/step - loss: 0.6968 - accuracy: 0.7052 - val_loss: 0.6828 - val_accuracy: 0.7120\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 789s 5s/step - loss: 0.6865 - accuracy: 0.7135 - val_loss: 0.6611 - val_accuracy: 0.7336\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 783s 5s/step - loss: 0.6787 - accuracy: 0.7145 - val_loss: 0.7092 - val_accuracy: 0.7042\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 781s 5s/step - loss: 0.6635 - accuracy: 0.7197 - val_loss: 0.6662 - val_accuracy: 0.7212\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 780s 5s/step - loss: 0.6637 - accuracy: 0.7155 - val_loss: 0.6765 - val_accuracy: 0.7297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 869s 5s/step - loss: 0.7469 - accuracy: 0.6954 - val_loss: 0.6419 - val_accuracy: 0.7514\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 870s 5s/step - loss: 0.5845 - accuracy: 0.7562 - val_loss: 0.6396 - val_accuracy: 0.7537\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 869s 5s/step - loss: 0.5452 - accuracy: 0.7786 - val_loss: 0.7296 - val_accuracy: 0.7205\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 869s 5s/step - loss: 0.5094 - accuracy: 0.8041 - val_loss: 0.5626 - val_accuracy: 0.7853\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 870s 5s/step - loss: 0.4904 - accuracy: 0.8007 - val_loss: 0.5033 - val_accuracy: 0.8085\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 860s 5s/step - loss: 0.4701 - accuracy: 0.8063 - val_loss: 0.4815 - val_accuracy: 0.8154\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 856s 5s/step - loss: 0.4466 - accuracy: 0.8211 - val_loss: 0.5050 - val_accuracy: 0.8147\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 857s 5s/step - loss: 0.4357 - accuracy: 0.8281 - val_loss: 0.5199 - val_accuracy: 0.8124\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 858s 5s/step - loss: 0.4053 - accuracy: 0.8376 - val_loss: 0.5974 - val_accuracy: 0.8031\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 857s 5s/step - loss: 0.3981 - accuracy: 0.8393 - val_loss: 0.5346 - val_accuracy: 0.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eb364b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: True\n",
      "Train DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "4468  4468.jpg                 2              44        2         reptile   \n",
      "3498  3498.jpg                 0              28        0            bird   \n",
      "6148  6148.jpg                 0              30        0            bird   \n",
      "354    354.jpg                 1              31        1             dog   \n",
      "4655  4655.jpg                 2              69        2         reptile   \n",
      "\n",
      "      index_y                                      subclass_name    class  \n",
      "4468       44              hognose snake, puff adder, sand viper  reptile  \n",
      "3498       28                                       black grouse     bird  \n",
      "6148       30                                            vulture     bird  \n",
      "354        31                                           Shih-Tzu      dog  \n",
      "4655       69  leatherback turtle, leatherback, leathery turt...  reptile  \n",
      "Validation DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "131    131.jpg                 0              26        0            bird   \n",
      "923    923.jpg                 2              15        2         reptile   \n",
      "940    940.jpg                 0              57        0            bird   \n",
      "1930  1930.jpg                 0              19        0            bird   \n",
      "3040  3040.jpg                 0              27        0            bird   \n",
      "\n",
      "      index_y                        subclass_name    class  \n",
      "131        26                 albatross, mollymawk     bird  \n",
      "923        15                           mud turtle  reptile  \n",
      "940        57                               bulbul     bird  \n",
      "1930       19  brambling, Fringilla montifringilla     bird  \n",
      "3040       27                  water ouzel, dipper     bird  \n",
      "Length of train_df: 5177\n",
      "Length of validation_df: 1295\n",
      "4468.jpg exists: True\n",
      "3498.jpg exists: True\n",
      "6148.jpg exists: True\n",
      "354.jpg exists: True\n",
      "4655.jpg exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Check the directory path\n",
    "print(\"Directory exists:\", os.path.isdir(image_folder_path))\n",
    "\n",
    "# Check the first few rows of train_df and validation_df\n",
    "print(\"Train DataFrame:\\n\", train_df.head())\n",
    "print(\"Validation DataFrame:\\n\", validation_df.head())\n",
    "\n",
    "# Check the length of the DataFrames\n",
    "print(\"Length of train_df:\", len(train_df))\n",
    "print(\"Length of validation_df:\", len(validation_df))\n",
    "\n",
    "# Check a few image file paths\n",
    "sample_images = train_df['image'].head().tolist()\n",
    "for img in sample_images:\n",
    "    file_path = os.path.join(image_folder_path, img)\n",
    "    print(f\"{img} exists:\", os.path.isfile(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
