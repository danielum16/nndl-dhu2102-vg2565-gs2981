{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/train_data.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>superclass_index</th>\n",
       "      <th>subclass_index</th>\n",
       "      <th>index_x</th>\n",
       "      <th>superclass_name</th>\n",
       "      <th>index_y</th>\n",
       "      <th>subclass_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "      <td>37</td>\n",
       "      <td>Maltese dog, Maltese terrier, Maltese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>bird</td>\n",
       "      <td>42</td>\n",
       "      <td>oystercatcher, oyster catcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "      <td>62</td>\n",
       "      <td>Afghan hound, Afghan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "      <td>31</td>\n",
       "      <td>Shih-Tzu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>bird</td>\n",
       "      <td>4</td>\n",
       "      <td>great grey owl, great gray owl, Strix nebulosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image  superclass_index  subclass_index  index_x superclass_name  index_y  \\\n",
       "0  0.jpg                 1              37        1             dog       37   \n",
       "1  1.jpg                 0              42        0            bird       42   \n",
       "2  2.jpg                 1              62        1             dog       62   \n",
       "3  3.jpg                 1              31        1             dog       31   \n",
       "4  4.jpg                 0               4        0            bird        4   \n",
       "\n",
       "                                    subclass_name  \n",
       "0           Maltese dog, Maltese terrier, Maltese  \n",
       "1                   oystercatcher, oyster catcher  \n",
       "2                            Afghan hound, Afghan  \n",
       "3                                        Shih-Tzu  \n",
       "4  great grey owl, great gray owl, Strix nebulosa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reptile    2388\n",
       "dog        2084\n",
       "bird       1850\n",
       "Name: superclass_name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df[\"superclass_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset class for multilabel classification\n",
    "class MultiClassImageDataset(Dataset):\n",
    "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
    "        self.ann_df = ann_df\n",
    "        self.super_map_df = super_map_df\n",
    "        self.sub_map_df = sub_map_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.ann_df['image'][idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        super_idx = self.ann_df['superclass_index'][idx]\n",
    "        super_label = self.super_map_df['class'][super_idx]\n",
    "\n",
    "        sub_idx = self.ann_df['subclass_index'][idx]\n",
    "        sub_label = self.sub_map_df['class'][sub_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, super_idx, super_label, sub_idx, sub_label\n",
    "\n",
    "class MultiClassImageTestDataset(Dataset):\n",
    "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
    "        self.super_map_df = super_map_df\n",
    "        self.sub_map_df = sub_map_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): # Count files in img_dir\n",
    "        return len([fname for fname in os.listdir(self.img_dir)])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx) + '.jpg'\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann_df = pd.read_csv('Released_Data/train_data.csv')\n",
    "super_map_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_map_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "train_img_dir = 'Released_Data/train_shuffle'\n",
    "test_img_dir = 'Released_Data/test_shuffle'\n",
    "\n",
    "image_preprocessing = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0), std=(1)),\n",
    "])\n",
    "\n",
    "# Create train and val split\n",
    "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
    "\n",
    "proportions = [.9, .1]\n",
    "lengths = [int(p * len(train_dataset)) for p in proportions]\n",
    "lengths[-1] = len(train_dataset) - sum(lengths[:-1])\n",
    "#train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n",
    "# Since I'm using PyTorch 1.1.0, I can't use the above line of code\n",
    "train_dataset, val_dataset = random_split(train_dataset, lengths)\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=1,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.MaxPool2d(2, 2)\n",
    "                      )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "                        nn.Conv2d(32, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.MaxPool2d(2, 2)\n",
    "                      )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "                        nn.Conv2d(64, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.MaxPool2d(2, 2)\n",
    "                      )\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3a = nn.Linear(128, 4)\n",
    "        self.fc3b = nn.Linear(128, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        super_out = self.fc3a(x)\n",
    "        sub_out = self.fc3b(x)\n",
    "        return super_out, sub_out\n",
    "\n",
    "resnet18_model = torchvision.models.resnet18()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "conv1\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "bn1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu\n",
      "ReLU(inplace=True)\n",
      "maxpool\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "layer1\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer1.0\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer1.0.conv1\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.0.bn1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.0.relu\n",
      "ReLU(inplace=True)\n",
      "layer1.0.conv2\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.0.bn2\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.1\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer1.1.conv1\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.1.bn1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.1.relu\n",
      "ReLU(inplace=True)\n",
      "layer1.1.conv2\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.1.bn2\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer2.0\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer2.0.conv1\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer2.0.bn1\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.0.relu\n",
      "ReLU(inplace=True)\n",
      "layer2.0.conv2\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.0.bn2\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.0.downsample\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer2.0.downsample.0\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer2.0.downsample.1\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer2.1.conv1\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.1.bn1\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1.relu\n",
      "ReLU(inplace=True)\n",
      "layer2.1.conv2\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.1.bn2\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer3.0\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer3.0.conv1\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer3.0.bn1\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.0.relu\n",
      "ReLU(inplace=True)\n",
      "layer3.0.conv2\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.0.bn2\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.0.downsample\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer3.0.downsample.0\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer3.0.downsample.1\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer3.1.conv1\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.1.bn1\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1.relu\n",
      "ReLU(inplace=True)\n",
      "layer3.1.conv2\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.1.bn2\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer4.0\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer4.0.conv1\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer4.0.bn1\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.0.relu\n",
      "ReLU(inplace=True)\n",
      "layer4.0.conv2\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.0.bn2\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.0.downsample\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer4.0.downsample.0\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer4.0.downsample.1\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer4.1.conv1\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.1.bn1\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1.relu\n",
      "ReLU(inplace=True)\n",
      "layer4.1.conv2\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.1.bn2\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "avgpool\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "fc\n",
      "Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# for name, param in resnet18_model.named_parameters():\n",
    "#     print(name)\n",
    "\n",
    "for n, m in resnet18_model.named_modules():\n",
    "  print(n)\n",
    "  print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet18_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTailModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        if model_name == 'resnet18':\n",
    "            self.resnet_model = torchvision.models.resnet18(pretrained=True)\n",
    "            # Replace classification head\n",
    "            self.resnet_model.fc = nn.Linear(512, 2000)\n",
    "            # non-linear MLP with one hidden layer\n",
    "            self.fe = nn.Sequential([\n",
    "                nn.Linear(2000, 2000), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2000, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 2000),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet_model(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fe(x)\n",
    "        return x\n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cpu'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            break\n",
    "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(inputs)\n",
    "            print(super_outputs.size())\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            # print(loss)\n",
    "            # print(loss.size())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            print(f\"Batch: {i}, Loss: {loss.item()}\")\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Training loss: {running_loss/i:.3f}')\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_predicted == super_labels).sum().item()\n",
    "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n",
    "        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n",
    "\n",
    "    def test(self, save_to_csv=False, return_predictions=False):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                inputs, img_name = data[0].to(self.device), data[1]\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(inputs)\n",
    "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
    "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
    "\n",
    "                test_predictions['image'].append(img_name[0])\n",
    "                test_predictions['superclass_index'].append(super_predicted.item())\n",
    "                test_predictions['subclass_index'].append(sub_predicted.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "\n",
    "        if return_predictions:\n",
    "            return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model and trainer\n",
    "device = 'cpu'\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "[tensor([[[[0.2392, 0.1961, 0.2118,  ..., 0.1686, 0.1176, 0.1098],\n",
      "          [0.2667, 0.3412, 0.4431,  ..., 0.0784, 0.0314, 0.0745],\n",
      "          [0.4549, 0.5294, 0.5843,  ..., 0.0471, 0.0549, 0.1216],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.2314, 0.3412, 0.2627],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.1882, 0.2157, 0.1490],\n",
      "          [1.0000, 1.0000, 0.9882,  ..., 0.0549, 0.0667, 0.1176]],\n",
      "\n",
      "         [[0.3529, 0.3098, 0.3216,  ..., 0.3686, 0.3137, 0.3059],\n",
      "          [0.3725, 0.4431, 0.5373,  ..., 0.2745, 0.2275, 0.2745],\n",
      "          [0.5333, 0.6118, 0.6549,  ..., 0.2431, 0.2510, 0.3216],\n",
      "          ...,\n",
      "          [1.0000, 0.9922, 1.0000,  ..., 0.2118, 0.3216, 0.2431],\n",
      "          [0.9686, 0.9412, 0.9294,  ..., 0.1686, 0.1961, 0.1294],\n",
      "          [0.9686, 0.9216, 0.8863,  ..., 0.0353, 0.0471, 0.0980]],\n",
      "\n",
      "         [[0.1333, 0.1373, 0.2235,  ..., 0.0039, 0.0275, 0.0588],\n",
      "          [0.1961, 0.3059, 0.4745,  ..., 0.0000, 0.0000, 0.0157],\n",
      "          [0.4235, 0.5451, 0.6627,  ..., 0.0000, 0.0000, 0.0588],\n",
      "          ...,\n",
      "          [0.7843, 0.7647, 0.7725,  ..., 0.1882, 0.2980, 0.2275],\n",
      "          [0.8078, 0.7725, 0.7608,  ..., 0.1529, 0.1804, 0.1137],\n",
      "          [0.8510, 0.8000, 0.7569,  ..., 0.0196, 0.0314, 0.0824]]],\n",
      "\n",
      "\n",
      "        [[[0.4235, 0.4353, 0.4549,  ..., 0.4431, 0.4510, 0.4510],\n",
      "          [0.4392, 0.4471, 0.4627,  ..., 0.4471, 0.4549, 0.4588],\n",
      "          [0.4588, 0.4627, 0.4706,  ..., 0.4549, 0.4627, 0.4667],\n",
      "          ...,\n",
      "          [0.4431, 0.4275, 0.4627,  ..., 0.5137, 0.5686, 0.4627],\n",
      "          [0.4549, 0.4314, 0.4588,  ..., 0.4431, 0.5098, 0.5725],\n",
      "          [0.4549, 0.4314, 0.4588,  ..., 0.5255, 0.5333, 0.5490]],\n",
      "\n",
      "         [[0.5098, 0.4980, 0.4902,  ..., 0.4314, 0.4235, 0.4235],\n",
      "          [0.4980, 0.4902, 0.4824,  ..., 0.4353, 0.4275, 0.4314],\n",
      "          [0.4863, 0.4784, 0.4745,  ..., 0.4471, 0.4392, 0.4431],\n",
      "          ...,\n",
      "          [0.4941, 0.4667, 0.4784,  ..., 0.5294, 0.5843, 0.4784],\n",
      "          [0.4941, 0.4627, 0.4745,  ..., 0.4667, 0.5373, 0.6039],\n",
      "          [0.4941, 0.4627, 0.4667,  ..., 0.5529, 0.5686, 0.6000]],\n",
      "\n",
      "         [[0.3294, 0.3529, 0.3843,  ..., 0.3725, 0.3922, 0.4000],\n",
      "          [0.3373, 0.3569, 0.3961,  ..., 0.3686, 0.3882, 0.4000],\n",
      "          [0.3529, 0.3804, 0.4196,  ..., 0.3647, 0.3843, 0.3961],\n",
      "          ...,\n",
      "          [0.3922, 0.3725, 0.4118,  ..., 0.4745, 0.5294, 0.4235],\n",
      "          [0.3882, 0.3725, 0.4157,  ..., 0.3647, 0.4039, 0.4431],\n",
      "          [0.3882, 0.3725, 0.4118,  ..., 0.4235, 0.3843, 0.3804]]],\n",
      "\n",
      "\n",
      "        [[[0.5020, 0.5020, 0.5020,  ..., 0.3804, 0.3804, 0.3843],\n",
      "          [0.4784, 0.4745, 0.4784,  ..., 0.4039, 0.4039, 0.4118],\n",
      "          [0.4745, 0.4706, 0.4706,  ..., 0.4196, 0.4235, 0.4314],\n",
      "          ...,\n",
      "          [0.4667, 0.4314, 0.3725,  ..., 0.5608, 0.5569, 0.5490],\n",
      "          [0.4902, 0.4706, 0.4275,  ..., 0.5647, 0.5608, 0.5490],\n",
      "          [0.4118, 0.4000, 0.3765,  ..., 0.4392, 0.4471, 0.4431]],\n",
      "\n",
      "         [[0.4510, 0.4510, 0.4471,  ..., 0.3647, 0.3686, 0.3804],\n",
      "          [0.4431, 0.4353, 0.4353,  ..., 0.3804, 0.3922, 0.4000],\n",
      "          [0.4392, 0.4353, 0.4353,  ..., 0.3961, 0.4118, 0.4196],\n",
      "          ...,\n",
      "          [0.4549, 0.4118, 0.3529,  ..., 0.5373, 0.5333, 0.5255],\n",
      "          [0.4980, 0.4667, 0.4235,  ..., 0.5373, 0.5333, 0.5216],\n",
      "          [0.4235, 0.4157, 0.3843,  ..., 0.4118, 0.4196, 0.4157]],\n",
      "\n",
      "         [[0.3176, 0.3255, 0.3333,  ..., 0.1765, 0.1686, 0.1686],\n",
      "          [0.2902, 0.2941, 0.3098,  ..., 0.1922, 0.1922, 0.1922],\n",
      "          [0.2706, 0.2745, 0.2824,  ..., 0.2078, 0.2118, 0.2118],\n",
      "          ...,\n",
      "          [0.2941, 0.2471, 0.1882,  ..., 0.4118, 0.4078, 0.4000],\n",
      "          [0.3137, 0.2863, 0.2353,  ..., 0.4235, 0.4196, 0.4078],\n",
      "          [0.2392, 0.2196, 0.1882,  ..., 0.2980, 0.3059, 0.3020]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3922, 0.4000, 0.4118,  ..., 0.3804, 0.3725, 0.3686],\n",
      "          [0.3961, 0.4000, 0.4157,  ..., 0.3843, 0.3765, 0.3725],\n",
      "          [0.4000, 0.4078, 0.4196,  ..., 0.3882, 0.3843, 0.3804],\n",
      "          ...,\n",
      "          [0.6353, 0.6510, 0.6706,  ..., 0.0980, 0.1333, 0.1490],\n",
      "          [0.6314, 0.6431, 0.6627,  ..., 0.1059, 0.1686, 0.2078],\n",
      "          [0.6275, 0.6392, 0.6510,  ..., 0.0745, 0.0824, 0.0941]],\n",
      "\n",
      "         [[0.3569, 0.3647, 0.3765,  ..., 0.3647, 0.3529, 0.3569],\n",
      "          [0.3608, 0.3647, 0.3765,  ..., 0.3686, 0.3608, 0.3529],\n",
      "          [0.3608, 0.3686, 0.3804,  ..., 0.3725, 0.3686, 0.3647],\n",
      "          ...,\n",
      "          [0.5294, 0.5451, 0.5647,  ..., 0.0510, 0.0863, 0.1020],\n",
      "          [0.5255, 0.5373, 0.5569,  ..., 0.0627, 0.1255, 0.1647],\n",
      "          [0.5216, 0.5333, 0.5529,  ..., 0.0392, 0.0471, 0.0588]],\n",
      "\n",
      "         [[0.3294, 0.3294, 0.3412,  ..., 0.3294, 0.3294, 0.3294],\n",
      "          [0.3255, 0.3294, 0.3412,  ..., 0.3255, 0.3255, 0.3294],\n",
      "          [0.3255, 0.3333, 0.3412,  ..., 0.3255, 0.3255, 0.3294],\n",
      "          ...,\n",
      "          [0.4235, 0.4314, 0.4471,  ..., 0.0667, 0.1020, 0.1098],\n",
      "          [0.4196, 0.4235, 0.4431,  ..., 0.0863, 0.1490, 0.1804],\n",
      "          [0.4157, 0.4275, 0.4353,  ..., 0.0588, 0.0667, 0.0784]]],\n",
      "\n",
      "\n",
      "        [[[0.4980, 0.4667, 0.4235,  ..., 0.3725, 0.3529, 0.4000],\n",
      "          [0.4902, 0.4275, 0.3804,  ..., 0.2941, 0.3020, 0.3255],\n",
      "          [0.4745, 0.4157, 0.3490,  ..., 0.2745, 0.3059, 0.2863],\n",
      "          ...,\n",
      "          [0.1137, 0.1451, 0.1451,  ..., 0.9216, 0.9373, 0.9412],\n",
      "          [0.1882, 0.1725, 0.1098,  ..., 0.9529, 0.9647, 0.9686],\n",
      "          [0.6314, 0.5059, 0.3020,  ..., 0.9294, 0.9451, 0.9569]],\n",
      "\n",
      "         [[0.5137, 0.5098, 0.5137,  ..., 0.4196, 0.3529, 0.3725],\n",
      "          [0.5059, 0.4667, 0.4627,  ..., 0.3451, 0.3098, 0.3098],\n",
      "          [0.4863, 0.4549, 0.4157,  ..., 0.3412, 0.3373, 0.2980],\n",
      "          ...,\n",
      "          [0.0588, 0.0706, 0.0510,  ..., 0.9412, 0.9333, 0.9176],\n",
      "          [0.1412, 0.1176, 0.0353,  ..., 0.9686, 0.9569, 0.9412],\n",
      "          [0.5961, 0.4588, 0.2275,  ..., 0.9451, 0.9333, 0.9255]],\n",
      "\n",
      "         [[0.2157, 0.2118, 0.2078,  ..., 0.2706, 0.2196, 0.2588],\n",
      "          [0.2157, 0.1804, 0.1686,  ..., 0.1765, 0.1569, 0.1647],\n",
      "          [0.2078, 0.1765, 0.1373,  ..., 0.1373, 0.1451, 0.1137],\n",
      "          ...,\n",
      "          [0.0235, 0.0431, 0.0353,  ..., 0.9137, 0.9255, 0.9255],\n",
      "          [0.0941, 0.0745, 0.0078,  ..., 0.9647, 0.9765, 0.9725],\n",
      "          [0.5373, 0.4118, 0.2000,  ..., 0.9569, 0.9686, 0.9765]]],\n",
      "\n",
      "\n",
      "        [[[0.2824, 0.2706, 0.2784,  ..., 0.1765, 0.0235, 0.0706],\n",
      "          [0.3137, 0.3373, 0.3882,  ..., 0.1569, 0.0863, 0.0549],\n",
      "          [0.3373, 0.3490, 0.3765,  ..., 0.0824, 0.0980, 0.0431],\n",
      "          ...,\n",
      "          [0.2000, 0.2000, 0.2039,  ..., 0.2235, 0.2549, 0.2431],\n",
      "          [0.2196, 0.2078, 0.2039,  ..., 0.2784, 0.3176, 0.3059],\n",
      "          [0.2392, 0.2235, 0.2078,  ..., 0.2745, 0.2863, 0.2510]],\n",
      "\n",
      "         [[0.1882, 0.1765, 0.1882,  ..., 0.1569, 0.0118, 0.0588],\n",
      "          [0.2314, 0.2588, 0.3098,  ..., 0.1373, 0.0745, 0.0431],\n",
      "          [0.2745, 0.2863, 0.3176,  ..., 0.0706, 0.0863, 0.0431],\n",
      "          ...,\n",
      "          [0.2039, 0.2000, 0.2000,  ..., 0.2039, 0.2353, 0.2235],\n",
      "          [0.2235, 0.2078, 0.2000,  ..., 0.2510, 0.2902, 0.2784],\n",
      "          [0.2431, 0.2235, 0.2078,  ..., 0.2471, 0.2588, 0.2235]],\n",
      "\n",
      "         [[0.1882, 0.1686, 0.1647,  ..., 0.1412, 0.0000, 0.0392],\n",
      "          [0.2118, 0.2314, 0.2667,  ..., 0.1137, 0.0471, 0.0235],\n",
      "          [0.2157, 0.2275, 0.2431,  ..., 0.0353, 0.0510, 0.0039],\n",
      "          ...,\n",
      "          [0.0471, 0.0588, 0.0784,  ..., 0.0902, 0.1176, 0.1059],\n",
      "          [0.0667, 0.0588, 0.0784,  ..., 0.1412, 0.1765, 0.1647],\n",
      "          [0.0784, 0.0745, 0.0745,  ..., 0.1333, 0.1451, 0.1098]]]]), tensor([2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 2, 2,\n",
      "        2, 0, 0, 0, 1, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 2, 2, 1,\n",
      "        2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1]), ('reptile', 'bird', 'bird', 'bird', 'dog', 'dog', 'reptile', 'reptile', 'dog', 'reptile', 'dog', 'bird', 'reptile', 'reptile', 'reptile', 'dog', 'dog', 'dog', 'reptile', 'dog', 'reptile', 'bird', 'reptile', 'reptile', 'reptile', 'bird', 'bird', 'bird', 'dog', 'reptile', 'reptile', 'dog', 'bird', 'reptile', 'dog', 'dog', 'dog', 'reptile', 'dog', 'dog', 'bird', 'bird', 'dog', 'dog', 'reptile', 'reptile', 'reptile', 'dog', 'reptile', 'dog', 'bird', 'dog', 'dog', 'dog', 'reptile', 'dog', 'dog', 'dog', 'dog', 'bird', 'bird', 'bird', 'dog', 'dog'), tensor([47, 60, 41, 84, 46, 46, 72, 39, 37, 44, 36, 78, 44, 29, 71,  7,  9, 62,\n",
      "        34, 65, 33, 24, 66, 43, 55,  5, 26, 84,  0, 44, 72, 45, 24, 52,  2, 62,\n",
      "        65, 29, 18, 36, 28, 75, 31, 25,  1, 76, 63, 38, 29, 77, 75, 36, 10, 79,\n",
      "        52, 49, 46, 23, 22, 82, 75, 24, 18, 38]), ('Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis', 'goldfinch, Carduelis carduelis', 'redshank, Tringa totanus', 'magpie', 'papillon', 'papillon', 'axolotl, mud puppy, Ambystoma mexicanum', 'frilled lizard, Chlamydosaurus kingi', 'Maltese dog, Maltese terrier, Maltese', 'hognose snake, puff adder, sand viper', 'basset, basset hound', 'indigo bunting, indigo finch, indigo bird, Passerina cyanea', 'hognose snake, puff adder, sand viper', 'spotted salamander, Ambystoma maculatum', 'Gila monster, Heloderma suspectum', 'Pekinese, Pekingese, Peke', 'Lhasa, Lhasa apso', 'Afghan hound, Afghan', 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui', 'beagle', 'common iguana, iguana, Iguana iguana', 'bald eagle, American eagle, Haliaeetus leucocephalus', 'green lizard, Lacerta viridis', 'American alligator, Alligator mississipiensis', 'loggerhead, loggerhead turtle, Caretta caretta', 'bustard', 'albatross, mollymawk', 'magpie', 'Scotch terrier, Scottish terrier, Scottie', 'hognose snake, puff adder, sand viper', 'axolotl, mud puppy, Ambystoma mexicanum', 'Australian terrier', 'bald eagle, American eagle, Haliaeetus leucocephalus', 'triceratops', 'standard schnauzer', 'Afghan hound, Afghan', 'beagle', 'spotted salamander, Ambystoma maculatum', 'Blenheim spaniel', 'basset, basset hound', 'black grouse', 'chickadee', 'Shih-Tzu', 'Airedale, Airedale terrier', 'African chameleon, Chamaeleo chamaeleon', 'green snake, grass snake', 'bullfrog, Rana catesbeiana', 'Sealyham terrier, Sealyham', 'spotted salamander, Ambystoma maculatum', 'silky terrier, Sydney silky', 'chickadee', 'basset, basset hound', 'Lakeland terrier', 'Boston bull, Boston terrier', 'triceratops', 'bloodhound, sleuthhound', 'papillon', 'Dandie Dinmont, Dandie Dinmont terrier', 'Japanese spaniel', 'ruddy turnstone, Arenaria interpres', 'chickadee', 'bald eagle, American eagle, Haliaeetus leucocephalus', 'Blenheim spaniel', 'Sealyham terrier, Sealyham')]\n",
      "torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VEDANT~1\\AppData\\Local\\Temp/ipykernel_4904/334491382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch+1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VEDANT~1\\AppData\\Local\\Temp/ipykernel_4904/3409694443.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training loss: {running_loss/i:.3f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(2):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    trainer.validate_epoch()\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
