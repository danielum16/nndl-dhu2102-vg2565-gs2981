{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 15:42:20.109193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5057 validated image filenames belonging to 3 classes.\n",
      "Found 1265 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/train_data.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')\n",
    "\n",
    "# Superclass_name (can replace with subclass_name depending on classification task)\n",
    "train_data_df['class'] = train_data_df['superclass_name']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, validation_df = train_test_split(train_data_df, test_size=0.2)\n",
    "\n",
    "# Initialize the ImageDataGenerator with EfficientNet's preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'Released_Data/train_shuffle'\n",
    "\n",
    "# Load and preprocess images for training\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load and preprocess images for validation\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(len(super_classes_df), activation='softmax')(x) # Number of classes\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>superclass_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>reptile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index superclass_name\n",
       "0      0            bird\n",
       "1      1             dog\n",
       "2      2         reptile\n",
       "3      3           novel"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(super_classes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 810s 5s/step - loss: 0.8752 - accuracy: 0.5940 - val_loss: 0.7654 - val_accuracy: 0.6749\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 786s 5s/step - loss: 0.7729 - accuracy: 0.6612 - val_loss: 0.7502 - val_accuracy: 0.6819\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 791s 5s/step - loss: 0.7368 - accuracy: 0.6813 - val_loss: 0.7336 - val_accuracy: 0.6981\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 791s 5s/step - loss: 0.7198 - accuracy: 0.6977 - val_loss: 0.7182 - val_accuracy: 0.7073\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 788s 5s/step - loss: 0.7003 - accuracy: 0.7025 - val_loss: 0.7092 - val_accuracy: 0.7066\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 793s 5s/step - loss: 0.6968 - accuracy: 0.7052 - val_loss: 0.6828 - val_accuracy: 0.7120\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 789s 5s/step - loss: 0.6865 - accuracy: 0.7135 - val_loss: 0.6611 - val_accuracy: 0.7336\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 783s 5s/step - loss: 0.6787 - accuracy: 0.7145 - val_loss: 0.7092 - val_accuracy: 0.7042\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 781s 5s/step - loss: 0.6635 - accuracy: 0.7197 - val_loss: 0.6662 - val_accuracy: 0.7212\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 780s 5s/step - loss: 0.6637 - accuracy: 0.7155 - val_loss: 0.6765 - val_accuracy: 0.7297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 869s 5s/step - loss: 0.7469 - accuracy: 0.6954 - val_loss: 0.6419 - val_accuracy: 0.7514\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 870s 5s/step - loss: 0.5845 - accuracy: 0.7562 - val_loss: 0.6396 - val_accuracy: 0.7537\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 869s 5s/step - loss: 0.5452 - accuracy: 0.7786 - val_loss: 0.7296 - val_accuracy: 0.7205\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 869s 5s/step - loss: 0.5094 - accuracy: 0.8041 - val_loss: 0.5626 - val_accuracy: 0.7853\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 870s 5s/step - loss: 0.4904 - accuracy: 0.8007 - val_loss: 0.5033 - val_accuracy: 0.8085\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 860s 5s/step - loss: 0.4701 - accuracy: 0.8063 - val_loss: 0.4815 - val_accuracy: 0.8154\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 856s 5s/step - loss: 0.4466 - accuracy: 0.8211 - val_loss: 0.5050 - val_accuracy: 0.8147\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 857s 5s/step - loss: 0.4357 - accuracy: 0.8281 - val_loss: 0.5199 - val_accuracy: 0.8124\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 858s 5s/step - loss: 0.4053 - accuracy: 0.8376 - val_loss: 0.5974 - val_accuracy: 0.8031\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 857s 5s/step - loss: 0.3981 - accuracy: 0.8393 - val_loss: 0.5346 - val_accuracy: 0.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eb364b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learnig_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_folder = 'Released_Data/test_shuffle'   # Correct path to your test images\n",
    "image_files = [os.path.join(test_image_folder, img) for img in os.listdir(test_image_folder) if img.endswith('.jpg')]\n",
    "test_df = pd.DataFrame(image_files, columns=['filename'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Released_Data/test_shuffle/9733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Released_Data/test_shuffle/63.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Released_Data/test_shuffle/6400.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Released_Data/test_shuffle/823.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Released_Data/test_shuffle/4217.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename\n",
       "0  Released_Data/test_shuffle/9733.jpg\n",
       "1    Released_Data/test_shuffle/63.jpg\n",
       "2  Released_Data/test_shuffle/6400.jpg\n",
       "3   Released_Data/test_shuffle/823.jpg\n",
       "4  Released_Data/test_shuffle/4217.jpg"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 1480s 4s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12377, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielum/Library/Mobile Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predicted_superclass_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_superclass_indices = np.argmax(predictions, axis=1)\n",
    "predicted_superclass_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = [f\"{i}.jpg\" for i in range(len(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'ID': image_filenames,\n",
    "    'Target': predicted_superclass_indices\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_superclass_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: True\n",
      "Train DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "4468  4468.jpg                 2              44        2         reptile   \n",
      "3498  3498.jpg                 0              28        0            bird   \n",
      "6148  6148.jpg                 0              30        0            bird   \n",
      "354    354.jpg                 1              31        1             dog   \n",
      "4655  4655.jpg                 2              69        2         reptile   \n",
      "\n",
      "      index_y                                      subclass_name    class  \n",
      "4468       44              hognose snake, puff adder, sand viper  reptile  \n",
      "3498       28                                       black grouse     bird  \n",
      "6148       30                                            vulture     bird  \n",
      "354        31                                           Shih-Tzu      dog  \n",
      "4655       69  leatherback turtle, leatherback, leathery turt...  reptile  \n",
      "Validation DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "131    131.jpg                 0              26        0            bird   \n",
      "923    923.jpg                 2              15        2         reptile   \n",
      "940    940.jpg                 0              57        0            bird   \n",
      "1930  1930.jpg                 0              19        0            bird   \n",
      "3040  3040.jpg                 0              27        0            bird   \n",
      "\n",
      "      index_y                        subclass_name    class  \n",
      "131        26                 albatross, mollymawk     bird  \n",
      "923        15                           mud turtle  reptile  \n",
      "940        57                               bulbul     bird  \n",
      "1930       19  brambling, Fringilla montifringilla     bird  \n",
      "3040       27                  water ouzel, dipper     bird  \n",
      "Length of train_df: 5177\n",
      "Length of validation_df: 1295\n",
      "4468.jpg exists: True\n",
      "3498.jpg exists: True\n",
      "6148.jpg exists: True\n",
      "354.jpg exists: True\n",
      "4655.jpg exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Check the directory path\n",
    "print(\"Directory exists:\", os.path.isdir(image_folder_path))\n",
    "\n",
    "# Check the first few rows of train_df and validation_df\n",
    "print(\"Train DataFrame:\\n\", train_df.head())\n",
    "print(\"Validation DataFrame:\\n\", validation_df.head())\n",
    "\n",
    "# Check the length of the DataFrames\n",
    "print(\"Length of train_df:\", len(train_df))\n",
    "print(\"Length of validation_df:\", len(validation_df))\n",
    "\n",
    "# Check a few image file paths\n",
    "sample_images = train_df['image'].head().tolist()\n",
    "for img in sample_images:\n",
    "    file_path = os.path.join(image_folder_path, img)\n",
    "    print(f\"{img} exists:\", os.path.isfile(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_csv(\"/res/superclass_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
