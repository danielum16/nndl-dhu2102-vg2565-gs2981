{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5057 validated image filenames belonging to 3 classes.\n",
      "Found 1265 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/train_data.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')\n",
    "\n",
    "# Superclass_name (can replace with subclass_name depending on classification task)\n",
    "train_data_df['class'] = train_data_df['superclass_name']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, validation_df = train_test_split(train_data_df, test_size=0.2)\n",
    "\n",
    "# Initialize the ImageDataGenerator with EfficientNet's preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'Released_Data/train_shuffle'\n",
    "\n",
    "# Load and preprocess images for training\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load and preprocess images for validation\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(len(super_classes_df)-1, activation='softmax')(x) # Number of classes\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>superclass_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>reptile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index superclass_name\n",
       "0      0            bird\n",
       "1      1             dog\n",
       "2      2         reptile\n",
       "3      3           novel"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(super_classes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "159/159 [==============================] - 1107s 7s/step - loss: 0.5264 - accuracy: 0.8028 - val_loss: 0.2936 - val_accuracy: 0.9036\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 1053s 7s/step - loss: 0.3345 - accuracy: 0.8796 - val_loss: 0.2336 - val_accuracy: 0.9217\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 1059s 7s/step - loss: 0.2898 - accuracy: 0.8956 - val_loss: 0.2091 - val_accuracy: 0.9289\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 1035s 7s/step - loss: 0.2607 - accuracy: 0.9047 - val_loss: 0.2032 - val_accuracy: 0.9296\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 1007s 6s/step - loss: 0.2567 - accuracy: 0.9045 - val_loss: 0.1825 - val_accuracy: 0.9368\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 1010s 6s/step - loss: 0.2331 - accuracy: 0.9193 - val_loss: 0.1759 - val_accuracy: 0.9423\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 1006s 6s/step - loss: 0.2311 - accuracy: 0.9199 - val_loss: 0.1802 - val_accuracy: 0.9407\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 1010s 6s/step - loss: 0.2210 - accuracy: 0.9243 - val_loss: 0.1617 - val_accuracy: 0.9494\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 1002s 6s/step - loss: 0.2069 - accuracy: 0.9262 - val_loss: 0.1600 - val_accuracy: 0.9494\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 1009s 6s/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.1568 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "learnig_rate is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielum/Library/Mobile Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Re-compile the model with a lower learning rate\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learnig_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Continue training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train_generator, validation_data\u001b[39m=\u001b[39mvalidation_generator, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/adam.py:108\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     92\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    107\u001b[0m ):\n\u001b[0;32m--> 108\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    109\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    110\u001b[0m         weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[1;32m    111\u001b[0m         clipnorm\u001b[39m=\u001b[39mclipnorm,\n\u001b[1;32m    112\u001b[0m         clipvalue\u001b[39m=\u001b[39mclipvalue,\n\u001b[1;32m    113\u001b[0m         global_clipnorm\u001b[39m=\u001b[39mglobal_clipnorm,\n\u001b[1;32m    114\u001b[0m         use_ema\u001b[39m=\u001b[39muse_ema,\n\u001b[1;32m    115\u001b[0m         ema_momentum\u001b[39m=\u001b[39mema_momentum,\n\u001b[1;32m    116\u001b[0m         ema_overwrite_frequency\u001b[39m=\u001b[39mema_overwrite_frequency,\n\u001b[1;32m    117\u001b[0m         jit_compile\u001b[39m=\u001b[39mjit_compile,\n\u001b[1;32m    118\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_learning_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_1 \u001b[39m=\u001b[39m beta_1\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:1094\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m mesh \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmesh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1093\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mesh \u001b[39m=\u001b[39m mesh\n\u001b[0;32m-> 1094\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m   1095\u001b[0m     name,\n\u001b[1;32m   1096\u001b[0m     weight_decay,\n\u001b[1;32m   1097\u001b[0m     clipnorm,\n\u001b[1;32m   1098\u001b[0m     clipvalue,\n\u001b[1;32m   1099\u001b[0m     global_clipnorm,\n\u001b[1;32m   1100\u001b[0m     use_ema,\n\u001b[1;32m   1101\u001b[0m     ema_momentum,\n\u001b[1;32m   1102\u001b[0m     ema_overwrite_frequency,\n\u001b[1;32m   1103\u001b[0m     jit_compile,\n\u001b[1;32m   1104\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1105\u001b[0m )\n\u001b[1;32m   1106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_with_dtensor \u001b[39m=\u001b[39m dtensor_utils\u001b[39m.\u001b[39mrunning_with_dtensor_strategy()\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:106\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variables \u001b[39m=\u001b[39m []\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_iteration_variable()\n\u001b[0;32m--> 106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_kwargs(kwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:142\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m is deprecated in the new Keras optimizer, please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlegacy optimizer, e.g., \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf.keras.optimizers.legacy.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m is not a valid argument, kwargs should be empty \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: learnig_rate is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learnig_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_folder = 'Released_Data/test_shuffle'   # Correct path to your test images\n",
    "image_files = [os.path.join(test_image_folder, img) for img in os.listdir(test_image_folder) if img.endswith('.jpg')]\n",
    "test_df = pd.DataFrame(image_files, columns=['filename'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Released_Data/test_shuffle/9733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Released_Data/test_shuffle/63.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Released_Data/test_shuffle/6400.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Released_Data/test_shuffle/823.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Released_Data/test_shuffle/4217.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename\n",
       "0  Released_Data/test_shuffle/9733.jpg\n",
       "1    Released_Data/test_shuffle/63.jpg\n",
       "2  Released_Data/test_shuffle/6400.jpg\n",
       "3   Released_Data/test_shuffle/823.jpg\n",
       "4  Released_Data/test_shuffle/4217.jpg"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 1480s 4s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12377, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielum/Library/Mobile Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielum/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/MSCS/Fall_2023/NNDL/Final%20Project/option3/nndl-dhu2102-vg2565-gs2981/efficient_net_daniel_superclass.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predicted_superclass_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_superclass_indices = np.argmax(predictions, axis=1)\n",
    "predicted_superclass_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = [f\"{i}.jpg\" for i in range(len(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'ID': image_filenames,\n",
    "    'Target': predicted_superclass_indices\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_superclass_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: True\n",
      "Train DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "4468  4468.jpg                 2              44        2         reptile   \n",
      "3498  3498.jpg                 0              28        0            bird   \n",
      "6148  6148.jpg                 0              30        0            bird   \n",
      "354    354.jpg                 1              31        1             dog   \n",
      "4655  4655.jpg                 2              69        2         reptile   \n",
      "\n",
      "      index_y                                      subclass_name    class  \n",
      "4468       44              hognose snake, puff adder, sand viper  reptile  \n",
      "3498       28                                       black grouse     bird  \n",
      "6148       30                                            vulture     bird  \n",
      "354        31                                           Shih-Tzu      dog  \n",
      "4655       69  leatherback turtle, leatherback, leathery turt...  reptile  \n",
      "Validation DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "131    131.jpg                 0              26        0            bird   \n",
      "923    923.jpg                 2              15        2         reptile   \n",
      "940    940.jpg                 0              57        0            bird   \n",
      "1930  1930.jpg                 0              19        0            bird   \n",
      "3040  3040.jpg                 0              27        0            bird   \n",
      "\n",
      "      index_y                        subclass_name    class  \n",
      "131        26                 albatross, mollymawk     bird  \n",
      "923        15                           mud turtle  reptile  \n",
      "940        57                               bulbul     bird  \n",
      "1930       19  brambling, Fringilla montifringilla     bird  \n",
      "3040       27                  water ouzel, dipper     bird  \n",
      "Length of train_df: 5177\n",
      "Length of validation_df: 1295\n",
      "4468.jpg exists: True\n",
      "3498.jpg exists: True\n",
      "6148.jpg exists: True\n",
      "354.jpg exists: True\n",
      "4655.jpg exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Check the directory path\n",
    "print(\"Directory exists:\", os.path.isdir(image_folder_path))\n",
    "\n",
    "# Check the first few rows of train_df and validation_df\n",
    "print(\"Train DataFrame:\\n\", train_df.head())\n",
    "print(\"Validation DataFrame:\\n\", validation_df.head())\n",
    "\n",
    "# Check the length of the DataFrames\n",
    "print(\"Length of train_df:\", len(train_df))\n",
    "print(\"Length of validation_df:\", len(validation_df))\n",
    "\n",
    "# Check a few image file paths\n",
    "sample_images = train_df['image'].head().tolist()\n",
    "for img in sample_images:\n",
    "    file_path = os.path.join(image_folder_path, img)\n",
    "    print(f\"{img} exists:\", os.path.isfile(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_csv(\"/res/superclass_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
