{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5093 validated image filenames belonging to 4 classes.\n",
      "Found 1274 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/archive_augmented/train_data_new.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')\n",
    "\n",
    "# Superclass_name (can replace with subclass_name depending on classification task)\n",
    "train_data_df['class'] = train_data_df['superclass_name']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, validation_df = train_test_split(train_data_df, test_size=0.2)\n",
    "\n",
    "# Initialize the ImageDataGenerator with EfficientNet's preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'Released_Data/train_shuffle_augmented'\n",
    "\n",
    "# Load and preprocess images for training\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load and preprocess images for validation\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(len(super_classes_df), activation='softmax')(x) # Number of classes\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Folder containing the jpg files\n",
    "# folder_path = 'Released_Data/novel_data_augmented'\n",
    "# files = sorted(os.listdir(folder_path))\n",
    "\n",
    "# # Starting number for renaming\n",
    "# start_number = 6322\n",
    "\n",
    "# # Check if the number of files is correct\n",
    "# if len(files) != 45:\n",
    "#     print(\"Error: There should be exactly 45 files in the folder.\")\n",
    "# else:\n",
    "#     for i, file in enumerate(files):\n",
    "#         # Construct the new file name\n",
    "#         new_file_name = f\"{start_number + i}.jpg\"\n",
    "\n",
    "#         # Construct full file paths\n",
    "#         old_file_path = os.path.join(folder_path, file)\n",
    "#         new_file_path = os.path.join(folder_path, new_file_name)\n",
    "\n",
    "#         # Rename the file\n",
    "#         os.rename(old_file_path, new_file_path)\n",
    "\n",
    "#     print(\"Files have been renamed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 1720s 10s/step - loss: 0.5716 - accuracy: 0.7907 - val_loss: 0.3622 - val_accuracy: 0.8705\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 1647s 10s/step - loss: 0.3547 - accuracy: 0.8771 - val_loss: 0.3061 - val_accuracy: 0.8893\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 1642s 10s/step - loss: 0.3067 - accuracy: 0.8881 - val_loss: 0.2624 - val_accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 1601s 10s/step - loss: 0.2798 - accuracy: 0.9071 - val_loss: 0.2759 - val_accuracy: 0.8925\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 1642s 10s/step - loss: 0.2556 - accuracy: 0.9132 - val_loss: 0.2411 - val_accuracy: 0.9215\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 1567s 10s/step - loss: 0.2492 - accuracy: 0.9132 - val_loss: 0.2380 - val_accuracy: 0.9152\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 1005s 6s/step - loss: 0.2368 - accuracy: 0.9179 - val_loss: 0.2184 - val_accuracy: 0.9301\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 970s 6s/step - loss: 0.2261 - accuracy: 0.9183 - val_loss: 0.2135 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 982s 6s/step - loss: 0.2180 - accuracy: 0.9238 - val_loss: 0.2152 - val_accuracy: 0.9341\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 979s 6s/step - loss: 0.2134 - accuracy: 0.9293 - val_loss: 0.2105 - val_accuracy: 0.9325\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 1170s 7s/step - loss: 0.2288 - accuracy: 0.9175 - val_loss: 0.1645 - val_accuracy: 0.9466\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 1152s 7s/step - loss: 0.1491 - accuracy: 0.9470 - val_loss: 0.1490 - val_accuracy: 0.9498\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 1131s 7s/step - loss: 0.1113 - accuracy: 0.9596 - val_loss: 0.1364 - val_accuracy: 0.9545\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 1107s 7s/step - loss: 0.1004 - accuracy: 0.9652 - val_loss: 0.1258 - val_accuracy: 0.9537\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 1074s 7s/step - loss: 0.0805 - accuracy: 0.9705 - val_loss: 0.1371 - val_accuracy: 0.9545\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 1092s 7s/step - loss: 0.0719 - accuracy: 0.9755 - val_loss: 0.1286 - val_accuracy: 0.9568\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 1092s 7s/step - loss: 0.0636 - accuracy: 0.9804 - val_loss: 0.1315 - val_accuracy: 0.9576\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1108s 7s/step - loss: 0.0589 - accuracy: 0.9782 - val_loss: 0.1267 - val_accuracy: 0.9584\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1109s 7s/step - loss: 0.0596 - accuracy: 0.9796 - val_loss: 0.1303 - val_accuracy: 0.9608\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1084s 7s/step - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.1377 - val_accuracy: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1befdf450>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_folder = 'Released_Data/test_shuffle'   # Correct path to your test images\n",
    "image_files = [os.path.join(test_image_folder, img) for img in os.listdir(test_image_folder) if img.endswith('.jpg')]\n",
    "test_df = pd.DataFrame(image_files, columns=['filename'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 1818s 5s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_superclass_indices = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Target\n",
       "0  0.jpg       1\n",
       "1  1.jpg       1\n",
       "2  2.jpg       1\n",
       "3  3.jpg       0\n",
       "4  4.jpg       0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_filenames = [f\"{i}.jpg\" for i in range(len(predictions))]\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': image_filenames,\n",
    "    'Target': predicted_superclass_indices\n",
    "})\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"res/superclass_pred_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
