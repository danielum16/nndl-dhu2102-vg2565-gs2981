{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5057 validated image filenames belonging to 87 classes.\n",
      "Found 1265 validated image filenames belonging to 87 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV files\n",
    "train_data_df = pd.read_csv('Released_Data/archive/train_data_new.csv')\n",
    "super_classes_df = pd.read_csv('Released_Data/superclass_mapping.csv')\n",
    "sub_classes_df = pd.read_csv('Released_Data/subclass_mapping.csv')\n",
    "\n",
    "# Rename\n",
    "super_classes_df.rename(columns={'class': 'superclass_name'}, inplace=True)\n",
    "sub_classes_df.rename(columns={'class': 'subclass_name'}, inplace=True)\n",
    "\n",
    "# Merge the class names with the training data\n",
    "train_data_df = train_data_df.merge(super_classes_df, left_on='superclass_index', right_on='index', how='left')\n",
    "train_data_df = train_data_df.merge(sub_classes_df, left_on='subclass_index', right_on='index', how='left')\n",
    "\n",
    "# Superclass_name (can replace with subclass_name depending on classification task)\n",
    "train_data_df['class'] = train_data_df['subclass_name']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, validation_df = train_test_split(train_data_df, test_size=0.2)\n",
    "\n",
    "# Initialize the ImageDataGenerator with EfficientNet's preprocess_input\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'Released_Data/train_shuffle'\n",
    "\n",
    "# Load and preprocess images for training\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load and preprocess images for validation\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    directory=image_folder_path,\n",
    "    x_col='image',\n",
    "    y_col='class',\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Actual number of subclasses: \n",
    "num_subclasses = train_data_df['subclass_index'].nunique()\n",
    "\n",
    "# Add custom top layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(num_subclasses , activation='softmax')(x) # Number of classes\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subclasses: 87\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique subclass indices\n",
    "num_subclasses = train_data_df['subclass_index'].nunique()\n",
    "print(\"Number of unique subclasses:\", num_subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "159/159 [==============================] - 1021s 6s/step - loss: 3.2420 - accuracy: 0.2806 - val_loss: 2.3384 - val_accuracy: 0.4427\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 980s 6s/step - loss: 2.1674 - accuracy: 0.5019 - val_loss: 1.9147 - val_accuracy: 0.5233\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 1046s 7s/step - loss: 1.8081 - accuracy: 0.5699 - val_loss: 1.7318 - val_accuracy: 0.5542\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 1008s 6s/step - loss: 1.5830 - accuracy: 0.6269 - val_loss: 1.5836 - val_accuracy: 0.5866\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 1013s 6s/step - loss: 1.4646 - accuracy: 0.6427 - val_loss: 1.4978 - val_accuracy: 0.6103\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 1028s 6s/step - loss: 1.3433 - accuracy: 0.6773 - val_loss: 1.4558 - val_accuracy: 0.6047\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 1017s 6s/step - loss: 1.2520 - accuracy: 0.6961 - val_loss: 1.4118 - val_accuracy: 0.6221\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 1035s 7s/step - loss: 1.1689 - accuracy: 0.7115 - val_loss: 1.3770 - val_accuracy: 0.6316\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 1043s 7s/step - loss: 1.1423 - accuracy: 0.7283 - val_loss: 1.3497 - val_accuracy: 0.6411\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 1058s 7s/step - loss: 1.0668 - accuracy: 0.7325 - val_loss: 1.3160 - val_accuracy: 0.6451\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 1221s 7s/step - loss: 0.9593 - accuracy: 0.7566 - val_loss: 1.1072 - val_accuracy: 0.6798\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 1195s 8s/step - loss: 0.7184 - accuracy: 0.8248 - val_loss: 1.0436 - val_accuracy: 0.6941\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 1161s 7s/step - loss: 0.6051 - accuracy: 0.8521 - val_loss: 1.0037 - val_accuracy: 0.7012\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 3255s 21s/step - loss: 0.5214 - accuracy: 0.8727 - val_loss: 0.9819 - val_accuracy: 0.7115\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 1195s 8s/step - loss: 0.4628 - accuracy: 0.8901 - val_loss: 0.9724 - val_accuracy: 0.7178\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 1458s 9s/step - loss: 0.4111 - accuracy: 0.8995 - val_loss: 0.9508 - val_accuracy: 0.7202\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 1728s 11s/step - loss: 0.3736 - accuracy: 0.9124 - val_loss: 0.9429 - val_accuracy: 0.7304\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 1805s 11s/step - loss: 0.3356 - accuracy: 0.9211 - val_loss: 0.9237 - val_accuracy: 0.7336\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 1784s 11s/step - loss: 0.2878 - accuracy: 0.9342 - val_loss: 0.9212 - val_accuracy: 0.7344\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 1787s 11s/step - loss: 0.2727 - accuracy: 0.9397 - val_loss: 0.9091 - val_accuracy: 0.7431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b71d45d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_folder = 'Released_Data/test_shuffle'   # Correct path to your test images\n",
    "image_files = [os.path.join(test_image_folder, img) for img in os.listdir(test_image_folder) if img.endswith('.jpg')]\n",
    "test_df = pd.DataFrame(image_files, columns=['filename'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Released_Data/test_shuffle/9733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Released_Data/test_shuffle/63.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Released_Data/test_shuffle/6400.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Released_Data/test_shuffle/823.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Released_Data/test_shuffle/4217.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename\n",
       "0  Released_Data/test_shuffle/9733.jpg\n",
       "1    Released_Data/test_shuffle/63.jpg\n",
       "2  Released_Data/test_shuffle/6400.jpg\n",
       "3   Released_Data/test_shuffle/823.jpg\n",
       "4  Released_Data/test_shuffle/4217.jpg"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 2969s 8s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51300862e-01, 1.04239192e-07, 6.18650256e-06, ...,\n",
       "        3.27369307e-05, 1.34536705e-07, 6.04311463e-05],\n",
       "       [6.70024529e-05, 9.42222050e-06, 2.77952622e-05, ...,\n",
       "        9.01447274e-05, 5.78850950e-06, 4.74755052e-06],\n",
       "       [4.50959414e-01, 5.32656813e-05, 4.51473607e-05, ...,\n",
       "        1.74179638e-03, 9.17537875e-07, 9.90388726e-05],\n",
       "       ...,\n",
       "       [1.21575158e-06, 5.71911301e-08, 3.70027533e-06, ...,\n",
       "        3.24344983e-05, 7.48405280e-03, 5.43535954e-08],\n",
       "       [3.59533879e-05, 2.87077364e-05, 5.86568092e-08, ...,\n",
       "        2.39243571e-04, 1.70933290e-05, 5.30179477e-06],\n",
       "       [1.47966458e-03, 1.17337164e-04, 1.15857727e-03, ...,\n",
       "        6.07504153e-05, 3.71942148e-02, 8.65577895e-05]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12377, 87)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 23,  0, ...,  6, 62, 74])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_subclass_indices = np.argmax(predictions, axis=1)\n",
    "predicted_subclass_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = [f\"{i}.jpg\" for i in range(len(predictions))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'ID': image_filenames,\n",
    "    'Target': predicted_subclass_indices\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"res/subclass_pred_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: True\n",
      "Train DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "4468  4468.jpg                 2              44        2         reptile   \n",
      "3498  3498.jpg                 0              28        0            bird   \n",
      "6148  6148.jpg                 0              30        0            bird   \n",
      "354    354.jpg                 1              31        1             dog   \n",
      "4655  4655.jpg                 2              69        2         reptile   \n",
      "\n",
      "      index_y                                      subclass_name    class  \n",
      "4468       44              hognose snake, puff adder, sand viper  reptile  \n",
      "3498       28                                       black grouse     bird  \n",
      "6148       30                                            vulture     bird  \n",
      "354        31                                           Shih-Tzu      dog  \n",
      "4655       69  leatherback turtle, leatherback, leathery turt...  reptile  \n",
      "Validation DataFrame:\n",
      "          image  superclass_index  subclass_index  index_x superclass_name  \\\n",
      "131    131.jpg                 0              26        0            bird   \n",
      "923    923.jpg                 2              15        2         reptile   \n",
      "940    940.jpg                 0              57        0            bird   \n",
      "1930  1930.jpg                 0              19        0            bird   \n",
      "3040  3040.jpg                 0              27        0            bird   \n",
      "\n",
      "      index_y                        subclass_name    class  \n",
      "131        26                 albatross, mollymawk     bird  \n",
      "923        15                           mud turtle  reptile  \n",
      "940        57                               bulbul     bird  \n",
      "1930       19  brambling, Fringilla montifringilla     bird  \n",
      "3040       27                  water ouzel, dipper     bird  \n",
      "Length of train_df: 5177\n",
      "Length of validation_df: 1295\n",
      "4468.jpg exists: True\n",
      "3498.jpg exists: True\n",
      "6148.jpg exists: True\n",
      "354.jpg exists: True\n",
      "4655.jpg exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Check the directory path\n",
    "print(\"Directory exists:\", os.path.isdir(image_folder_path))\n",
    "\n",
    "# Check the first few rows of train_df and validation_df\n",
    "print(\"Train DataFrame:\\n\", train_df.head())\n",
    "print(\"Validation DataFrame:\\n\", validation_df.head())\n",
    "\n",
    "# Check the length of the DataFrames\n",
    "print(\"Length of train_df:\", len(train_df))\n",
    "print(\"Length of validation_df:\", len(validation_df))\n",
    "\n",
    "# Check a few image file paths\n",
    "sample_images = train_df['image'].head().tolist()\n",
    "for img in sample_images:\n",
    "    file_path = os.path.join(image_folder_path, img)\n",
    "    print(f\"{img} exists:\", os.path.isfile(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_csv(\"/res/superclass_pred_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
